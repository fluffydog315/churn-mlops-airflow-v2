{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e850e618",
   "metadata": {},
   "source": [
    "# Churn Exploration & Baseline Model\n",
    "Notebook to:\n",
    "1) Load the **fleet_churn.csv** (or `fleet_churn_30.csv`)\n",
    "2) Preprocess → one-hot encode categoricals\n",
    "3) Train **XGBoost** baseline\n",
    "4) Evaluate: ROC AUC, confusion matrix, classification report\n",
    "5) Plot ROC curve and Feature Importances\n",
    "\n",
    "> Tip: run this inside your project venv where `xgboost`, `pandas`, and `scikit-learn` are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8690edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost pandas scikit-learn matplotlib pyarrow\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "CSV_CANDIDATES = [\n",
    "    DATA_DIR / \"fleet_churn.csv\",\n",
    "    DATA_DIR / \"fleet_churn_30.csv\",\n",
    "]\n",
    "\n",
    "# Find dataset\n",
    "for p in CSV_CANDIDATES:\n",
    "    if p.exists():\n",
    "        data_path = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Put fleet_churn.csv or fleet_churn_30.csv under ./data/\")\n",
    "\n",
    "print(\"Using dataset:\", data_path)\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c905b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning and target\n",
    "assert \"churn\" in df.columns, \"Expected a 'churn' target column.\"\n",
    "y = df[\"churn\"].astype(int).values\n",
    "X = df.drop(columns=[\"churn\", \"customer_id\"], errors=\"ignore\").copy()\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "X[cat_cols] = X[cat_cols].fillna(\"NA\")\n",
    "X = pd.get_dummies(X, columns=cat_cols, dummy_na=False)\n",
    "\n",
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91c240f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train a baseline XGBoost model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mXGBClassifier\u001b[49m(\n\u001b[1;32m      3\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m      4\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m      5\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m      6\u001b[0m     subsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m      7\u001b[0m     colsample_bytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[1;32m      8\u001b[0m     reg_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m      9\u001b[0m     reg_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     10\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     12\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     16\u001b[0m proba_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a baseline XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "proba_val = model.predict_proba(X_val)[:, 1]\n",
    "pred_val = (proba_val >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_val, proba_val)\n",
    "print(\"Validation ROC AUC:\", round(float(auc), 4))\n",
    "print()\n",
    "print(classification_report(y_val, pred_val, digits=4))\n",
    "cm = confusion_matrix(y_val, pred_val)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f645c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve (matplotlib only; no style/colors specified)\n",
    "fpr, tpr, thr = roc_curve(y_val, proba_val)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {auc:.3f}')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve — XGBoost (Validation)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53258b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances (gain-based)\n",
    "importances = model.feature_importances_\n",
    "feat_imp = (\n",
    "    pd.DataFrame({\"feature\": X_train.columns, \"importance\": importances})\n",
    "      .sort_values(\"importance\", ascending=False)\n",
    "      .head(25)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "feat_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top feature importances (matplotlib only)\n",
    "plt.figure(figsize=(7, 8))\n",
    "plt.barh(feat_imp[\"feature\"][::-1], feat_imp[\"importance\"][::-1])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(\"Top 25 Feature Importances — XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcbeec4",
   "metadata": {},
   "source": [
    "## Save the trained model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90137ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to disk for reuse (optional)\n",
    "from joblib import dump\n",
    "models_dir = Path(\"models\"); models_dir.mkdir(parents=True, exist_ok=True)\n",
    "dump(model, models_dir / \"notebook_xgb_model.pkl\")\n",
    "print(\"Saved:\", models_dir / \"notebook_xgb_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42707c0-3aa6-4145-b02b-c9806260ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_auc: 0.5325090909090909\n",
      "val_f1 @0.5: 0.1814516129032258\n"
     ]
    }
   ],
   "source": [
    "import json, glob, os, pandas as pd\n",
    "\n",
    "# read our saved metrics from training logs (fallback: parse Airflow log or recompute quickly)\n",
    "# here we compute quickly from val.parquet to be definitive:\n",
    "val = pd.read_parquet(\"data/processed/val.parquet\")\n",
    "y = val[\"label\"].values\n",
    "X = val.drop(columns=[\"label\"])\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "proba = joblib.load(\"models/latest_model.pkl\").predict_proba(X)[:,1]\n",
    "print(\"val_auc:\", roc_auc_score(y, proba))\n",
    "print(\"val_f1 @0.5:\", f1_score(y, (proba>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d3f96a-060c-4d96-81a8-2d76759a67c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 4800 cols: 28\n",
      "label mean (train): 0.30395833333333333\n",
      "first 5 cols: ['tenure_months', 'num_vehicles', 'avg_card_swipes_per_vehicle', 'monthly_txn_count', 'monthly_spend']\n"
     ]
    }
   ],
   "source": [
    "# how many features?\n",
    "#python - <<'PY'\n",
    "import pandas as pd; df=pd.read_parquet(\"data/processed/train.parquet\")\n",
    "print(\"rows:\", len(df), \"cols:\", df.shape[1])\n",
    "print(\"label mean (train):\", df[\"label\"].mean())\n",
    "print(\"first 5 cols:\", list(df.columns[:5]))\n",
    "#PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7262ee07-1cb9-4d98-abe2-210e80e29f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
